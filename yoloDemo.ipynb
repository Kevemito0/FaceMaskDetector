{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ultralytics/yolov5\n",
    "# %cd yolov5\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import xml.etree.ElementTree as ET \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = r\"C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\"\n",
    "output_data = r\"C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = os.path.join(input_data, \"annotations\")\n",
    "images_path = os.path.join(input_data, \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "            \"file\":[],\n",
    "            \"name\":[],    \n",
    "            \"width\":[],\n",
    "            \"height\":[],\n",
    "            \"xmin\":[],\n",
    "            \"ymin\":[],   \n",
    "            \"xmax\":[],\n",
    "            \"ymax\":[],\n",
    "           }\n",
    "\n",
    "for anno in glob.glob(annotations_path+\"/*.xml\"):\n",
    "    tree = ET.parse(anno)\n",
    "    \n",
    "    for elem in tree.iter():\n",
    "        if 'size' in elem.tag:\n",
    "            for attr in list(elem):\n",
    "                if 'width' in attr.tag: \n",
    "                    width = int(round(float(attr.text)))\n",
    "                if 'height' in attr.tag:\n",
    "                    height = int(round(float(attr.text)))    \n",
    "\n",
    "        if 'object' in elem.tag:\n",
    "            for attr in list(elem):\n",
    "                \n",
    "                if 'name' in attr.tag:\n",
    "                    name = attr.text                 \n",
    "                    dataset['name']+=[name]\n",
    "                    dataset['width']+=[width]\n",
    "                    dataset['height']+=[height] \n",
    "                    dataset['file']+=[os.path.basename(anno).split('.')[0]]\n",
    "                            \n",
    "                if 'bndbox' in attr.tag:\n",
    "                    for dim in list(attr):\n",
    "                        if 'xmin' in dim.tag:\n",
    "                            xmin = int(round(float(dim.text)))\n",
    "                            dataset['xmin']+=[xmin]\n",
    "                        if 'ymin' in dim.tag:\n",
    "                            ymin = int(round(float(dim.text)))\n",
    "                            dataset['ymin']+=[ymin]                                \n",
    "                        if 'xmax' in dim.tag:\n",
    "                            xmax = int(round(float(dim.text)))\n",
    "                            dataset['xmax']+=[xmax]                                \n",
    "                        if 'ymax' in dim.tag:\n",
    "                            ymax = int(round(float(dim.text)))\n",
    "                            dataset['ymax']+=[ymax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>name</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maksssksksss0</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>512</td>\n",
       "      <td>366</td>\n",
       "      <td>79</td>\n",
       "      <td>105</td>\n",
       "      <td>109</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maksssksksss0</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>512</td>\n",
       "      <td>366</td>\n",
       "      <td>185</td>\n",
       "      <td>100</td>\n",
       "      <td>226</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maksssksksss0</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>512</td>\n",
       "      <td>366</td>\n",
       "      <td>325</td>\n",
       "      <td>90</td>\n",
       "      <td>360</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maksssksksss1</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>400</td>\n",
       "      <td>156</td>\n",
       "      <td>321</td>\n",
       "      <td>34</td>\n",
       "      <td>354</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maksssksksss1</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>400</td>\n",
       "      <td>156</td>\n",
       "      <td>224</td>\n",
       "      <td>38</td>\n",
       "      <td>261</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            file          name  width  height  xmin  ymin  xmax  ymax\n",
       "0  maksssksksss0  without_mask    512     366    79   105   109   142\n",
       "1  maksssksksss0     with_mask    512     366   185   100   226   144\n",
       "2  maksssksksss0  without_mask    512     366   325    90   360   141\n",
       "3  maksssksksss1     with_mask    400     156   321    34   354    69\n",
       "4  maksssksksss1     with_mask    400     156   224    38   261    73"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {\n",
    "    'with_mask': 0,\n",
    "    'mask_weared_incorrect': 1,\n",
    "    'without_mask': 2 \n",
    "}\n",
    "\n",
    "df['class'] = df['name'].map(name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mask_weared_incorrect', 'with_mask', 'without_mask'], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(df.name.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 853 images in the dataset\n"
     ]
    }
   ],
   "source": [
    "fileNames = [*os.listdir(images_path)]\n",
    "print('There are {} images in the dataset'.format(len(fileNames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train = 767\n",
      "==============================\n",
      "Length of Valid = 61\n",
      "==============================\n",
      "Length of test = 25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(fileNames, test_size=0.1, random_state=22)\n",
    "test, val = train_test_split(test, test_size=0.7, random_state=22)\n",
    "print(\"Length of Train =\",len(train))\n",
    "print(\"=\"*30)\n",
    "print(\"Length of Valid =\",len(val))\n",
    "print(\"=\"*30)\n",
    "print(\"Length of test =\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary directories if they do not exist\n",
    "os.makedirs(os.path.join(output_data, 'yolov5/data/train/images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_data, 'yolov5/data/train/labels'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_data, 'yolov5/data/val/images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_data, 'yolov5/data/val/labels'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_data, 'yolov5/data/test/images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_data, 'yolov5/data/test/labels'), exist_ok=True)\n",
    "\n",
    "# Change the working directory\n",
    "os.chdir(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def copyImages(imageList, folder_Name):\n",
    "    for image in imageList:\n",
    "        img = Image.open(input_data+\"/images/\"+image)\n",
    "        img1 = img.resize((640, 480))\n",
    "        _ = img1.save(output_data+\"/yolov5/data/\"+folder_Name+\"/images/\"+image)\n",
    "\n",
    "copyImages(train, \"train\")\n",
    "copyImages(val, \"val\")\n",
    "copyImages(test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>name</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maksssksksss0</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>512</td>\n",
       "      <td>366</td>\n",
       "      <td>79</td>\n",
       "      <td>105</td>\n",
       "      <td>109</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maksssksksss0</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>512</td>\n",
       "      <td>366</td>\n",
       "      <td>185</td>\n",
       "      <td>100</td>\n",
       "      <td>226</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maksssksksss0</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>512</td>\n",
       "      <td>366</td>\n",
       "      <td>325</td>\n",
       "      <td>90</td>\n",
       "      <td>360</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maksssksksss1</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>400</td>\n",
       "      <td>156</td>\n",
       "      <td>321</td>\n",
       "      <td>34</td>\n",
       "      <td>354</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maksssksksss1</td>\n",
       "      <td>with_mask</td>\n",
       "      <td>400</td>\n",
       "      <td>156</td>\n",
       "      <td>224</td>\n",
       "      <td>38</td>\n",
       "      <td>261</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            file          name  width  height  xmin  ymin  xmax  ymax  class\n",
       "0  maksssksksss0  without_mask    512     366    79   105   109   142      2\n",
       "1  maksssksksss0     with_mask    512     366   185   100   226   144      0\n",
       "2  maksssksksss0  without_mask    512     366   325    90   360   141      2\n",
       "3  maksssksksss1     with_mask    400     156   321    34   354    69      0\n",
       "4  maksssksksss1     with_mask    400     156   224    38   261    73      0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['xmax'] = (640/df['width'])*df['xmax']\n",
    "df['ymax'] = (480/df['height'])*df['ymax']\n",
    "df['xmin'] = (640/df['width'])*df['xmin']\n",
    "df['ymin'] = (480/df['height'])*df['ymin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['xmax', 'ymax', 'xmin', 'ymin']] = df[['xmax', 'ymax', 'xmin', 'ymin']].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x_center'] = (df['xmax']+df['xmin'])/(2*640)\n",
    "df['y_center'] = (df['ymax']+df['ymin'])/(2*480)\n",
    "df['box_height'] = (df['xmax']-df['xmin'])/(640)\n",
    "df['box_width'] = (df['ymax']-df['ymin'])/(480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(image_list, data_name):\n",
    "    fileNames = [x.split(\".\")[0] for x in image_list]\n",
    "    \n",
    "    for name in fileNames:\n",
    "        data = df[df.file==name]\n",
    "        \n",
    "        box_list = []\n",
    "        \n",
    "        for index in range(len(data)):\n",
    "            row = data.iloc[index]\n",
    "            box_list.append(row['class']+\" \"+row[\"x_center\"]+\" \"+row[\"y_center\"]\\\n",
    "                        +\" \"+row[\"box_height\"]+\" \"+row[\"box_width\"])\n",
    "            \n",
    "        text = \"\\n\".join(box_list)\n",
    "        with open(output_data+\"/yolov5/data/\"+data_name+\"/labels/\"+name+\".txt\", \"w\") as file:\n",
    "            file.write(text)\n",
    "\n",
    "\n",
    "create_labels(train, \"train\")\n",
    "create_labels(val, \"val\")\n",
    "create_labels(test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2025-1-4 Python-3.12.8 torch-2.5.1+cpu CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete  (12 CPUs, 31.1 GB RAM, 893.7/930.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# to display images\n",
    "from IPython.display import Image, clear_output\n",
    "import torch\n",
    "from yolov5 import utils\n",
    "display = utils.notebook_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaml_text = \"\"\"train: data/train/images\n",
    "# val: data/train/images\n",
    "\n",
    "# nc: 3\n",
    "# names: ['with_mask', 'mask_weared_incorrect', 'without_mask']\"\"\"\n",
    "\n",
    "# with open(\"data/data.yaml\", 'w') as file:\n",
    "#     file.write(yaml_text)\n",
    "\n",
    "# # %cat data/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/custom_yolov5s.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwritetemplate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/custom_yolov5s.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m# parameters\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mnc: 3  # number of classes\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdepth_multiple: 0.33  # model depth multiple\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mwidth_multiple: 0.50  # layer channel multiple\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# anchors\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43manchors:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    - [10,13, 16,30, 33,23]  # P3/8\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    - [30,61, 62,45, 59,119]  # P4/16\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    - [116,90, 156,198, 373,326]  # P5/32\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# YOLOv5 backbone\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mbackbone:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  # [from, number, module, args]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m   [-1, 3, BottleneckCSP, [128]],\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m   [-1, 9, BottleneckCSP, [256]],\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m   [-1, 9, BottleneckCSP, [512]],\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m   [-1, 1, SPP, [1024, [5, 9, 13]]],\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m   [-1, 3, BottleneckCSP, [1024, False]],  # 9\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  ]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# YOLOv5 head\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mhead:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    [[-1, 1, Conv, [512, 1, 1]],\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    [-1, 1, nn.Upsample, [None, 2, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnearest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]],\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    [[-1, 6], 1, Concat, [1]],  # cat backbone P4\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    [-1, 3, BottleneckCSP, [512, False]],  # 13\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    [-1, 1, Conv, [256, 1, 1]],\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    [-1, 1, nn.Upsample, [None, 2, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnearest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]],\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    [[-1, 4], 1, Concat, [1]],  # cat backbone P3\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    [-1, 1, Conv, [256, 3, 2]],\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    [[-1, 14], 1, Concat, [1]],  # cat head P4\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    [-1, 1, Conv, [512, 3, 2]],\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    [[-1, 10], 1, Concat, [1]],  # cat head P5\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    ]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:2541\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2539\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m   2540\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[1;32m-> 2541\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2543\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2544\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2545\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "Cell \u001b[1;32mIn[76], line 5\u001b[0m, in \u001b[0;36mwritetemplate\u001b[1;34m(line, cell)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;129m@register_line_cell_magic\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwritetemplate\u001b[39m(line, cell):\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(cell\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mglobals\u001b[39m()))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/custom_yolov5s.yaml'"
     ]
    }
   ],
   "source": [
    "# %%writetemplate models/custom_yolov5s.yaml\n",
    "# # parameters\n",
    "# nc: 3  # number of classes\n",
    "# depth_multiple: 0.33  # model depth multiple\n",
    "# width_multiple: 0.50  # layer channel multiple\n",
    "\n",
    "# # anchors\n",
    "# anchors:\n",
    "#     - [10,13, 16,30, 33,23]  # P3/8\n",
    "#     - [30,61, 62,45, 59,119]  # P4/16\n",
    "#     - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "# # YOLOv5 backbone\n",
    "# backbone:\n",
    "#   # [from, number, module, args]\n",
    "#   [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
    "#    [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "#    [-1, 3, BottleneckCSP, [128]],\n",
    "#    [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "#    [-1, 9, BottleneckCSP, [256]],\n",
    "#    [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "#    [-1, 9, BottleneckCSP, [512]],\n",
    "#    [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "#    [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
    "#    [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
    "#   ]\n",
    "\n",
    "# # YOLOv5 head\n",
    "# head:\n",
    "#     [[-1, 1, Conv, [512, 1, 1]],\n",
    "#     [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "#     [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "#     [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
    "\n",
    "#     [-1, 1, Conv, [256, 1, 1]],\n",
    "#     [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "#     [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "#     [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "#     [-1, 1, Conv, [256, 3, 2]],\n",
    "#     [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "#     [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "#     [-1, 1, Conv, [512, 3, 2]],\n",
    "#     [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "#     [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
    "\n",
    "#     [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\models\\custom_yolov5s.yaml, data=C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\data.yaml, hyp=yolov5\\data\\hyps\\hyp.scratch-low.yaml, epochs=50, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=yolov5\\data\\hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5\\runs\\train, name=yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 \n",
      "YOLOv5  v7.0-392-gf003c3df Python-3.12.8 torch-2.5.1+cpu CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5\\runs\\train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  3    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "custom_YOLOv5s summary: 233 layers, 7260488 parameters, 7260488 gradients\n",
      "\n",
      "Transferred 223/369 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 59 weight(decay=0.0), 70 weight(decay=0.0005), 62 bias\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\labels...:   0%|          | 0/25 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\labels... 1 images, 0 backgrounds, 0 corrupt:   4%|▍         | 1/25 [00:08<03:18,  8.27s/it]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\labels... 22 images, 0 backgrounds, 0 corrupt:  88%|████████▊ | 22/25 [00:08<00:00,  3.68it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\labels... 25 images, 0 backgrounds, 0 corrupt: 100%|██████████| 25/25 [00:08<00:00,  2.98it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  Cache directory C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test is not writeable: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\Kevem\\\\OneDrive\\\\Documents\\\\GitHub\\\\FaceMaskDetector\\\\Dataset\\\\Output\\\\yolov5\\\\data\\\\test\\\\labels.cache.npy' -> 'C:\\\\Users\\\\Kevem\\\\OneDrive\\\\Documents\\\\GitHub\\\\FaceMaskDetector\\\\Dataset\\\\Output\\\\yolov5\\\\data\\\\test\\\\labels.cache'\n",
      "\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100%|██████████| 25/25 [00:00<00:00, 1158.78it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\val\\labels...:   0%|          | 0/61 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\val\\labels... 1 images, 0 backgrounds, 0 corrupt:   2%|▏         | 1/61 [00:08<08:27,  8.45s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\val\\labels... 17 images, 0 backgrounds, 0 corrupt:  28%|██▊       | 17/61 [00:08<00:15,  2.77it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\val\\labels... 45 images, 0 backgrounds, 0 corrupt:  74%|███████▍  | 45/61 [00:08<00:01,  9.19it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\val\\labels... 61 images, 0 backgrounds, 0 corrupt: 100%|██████████| 61/61 [00:08<00:00,  7.02it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\val\\labels.cache\n",
      "\n",
      "  0%|          | 0/61 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100%|██████████| 61/61 [00:00<00:00, 1174.16it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.64 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to yolov5\\runs\\train\\yolov5s_results4\\labels.jpg... \n",
      "C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:355: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1myolov5\\runs\\train\\yolov5s_results4\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "       0/49         0G     0.1137    0.08632    0.03774        370        640:   0%|          | 0/1 [00:21<?, ?it/s]\n",
      "       0/49         0G     0.1137    0.08632    0.03774        370        640: 100%|██████████| 1/1 [00:23<00:00, 23.39s/it]\n",
      "       0/49         0G     0.1137    0.08632    0.03774        370        640: 100%|██████████| 1/1 [00:23<00:00, 23.40s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.67s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.67s/it]\n",
      "                   all         61        256   0.000333    0.00623   0.000171   2.55e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "       1/49         0G     0.1118    0.07417    0.03772        243        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "       1/49         0G     0.1118    0.07417    0.03772        243        640: 100%|██████████| 1/1 [00:07<00:00,  7.55s/it]\n",
      "       1/49         0G     0.1118    0.07417    0.03772        243        640: 100%|██████████| 1/1 [00:07<00:00,  7.55s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.82s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.82s/it]\n",
      "                   all         61        256   0.000175    0.00312   8.88e-05   1.78e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "       2/49         0G     0.1142    0.09527    0.03751        421        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "       2/49         0G     0.1142    0.09527    0.03751        421        640: 100%|██████████| 1/1 [00:07<00:00,  7.58s/it]\n",
      "       2/49         0G     0.1142    0.09527    0.03751        421        640: 100%|██████████| 1/1 [00:07<00:00,  7.58s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.63s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.63s/it]\n",
      "                   all         61        256    0.00037    0.00779    0.00019   2.66e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "       3/49         0G     0.1097    0.07837    0.03762        285        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       3/49         0G     0.1097    0.07837    0.03762        285        640: 100%|██████████| 1/1 [00:06<00:00,  6.88s/it]\n",
      "       3/49         0G     0.1097    0.07837    0.03762        285        640: 100%|██████████| 1/1 [00:06<00:00,  6.88s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.53s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.53s/it]\n",
      "                   all         61        256   0.000397    0.00779   0.000206   2.87e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "       4/49         0G       0.11    0.09069     0.0373        313        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       4/49         0G       0.11    0.09069     0.0373        313        640: 100%|██████████| 1/1 [00:06<00:00,  6.96s/it]\n",
      "       4/49         0G       0.11    0.09069     0.0373        313        640: 100%|██████████| 1/1 [00:06<00:00,  6.96s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.42s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.42s/it]\n",
      "                   all         61        256   0.000397    0.00779   0.000207   2.47e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "       5/49         0G     0.1125    0.09206    0.03741        431        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       5/49         0G     0.1125    0.09206    0.03741        431        640: 100%|██████████| 1/1 [00:06<00:00,  6.82s/it]\n",
      "       5/49         0G     0.1125    0.09206    0.03741        431        640: 100%|██████████| 1/1 [00:06<00:00,  6.82s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.52s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.52s/it]\n",
      "                   all         61        256   0.000513    0.00935    0.00027   4.01e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "       6/49         0G     0.1099    0.09371    0.03703        355        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       6/49         0G     0.1099    0.09371    0.03703        355        640: 100%|██████████| 1/1 [00:06<00:00,  6.79s/it]\n",
      "       6/49         0G     0.1099    0.09371    0.03703        355        640: 100%|██████████| 1/1 [00:06<00:00,  6.79s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.32s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.32s/it]\n",
      "                   all         61        256   0.000476    0.00935   0.000251   3.73e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "       7/49         0G     0.1094    0.07841    0.03699        269        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       7/49         0G     0.1094    0.07841    0.03699        269        640: 100%|██████████| 1/1 [00:06<00:00,  6.67s/it]\n",
      "       7/49         0G     0.1094    0.07841    0.03699        269        640: 100%|██████████| 1/1 [00:06<00:00,  6.67s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.49s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.49s/it]\n",
      "                   all         61        256   0.000635     0.0125   0.000343   5.88e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "       8/49         0G     0.1073    0.09892    0.03684        332        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       8/49         0G     0.1073    0.09892    0.03684        332        640: 100%|██████████| 1/1 [00:06<00:00,  6.79s/it]\n",
      "       8/49         0G     0.1073    0.09892    0.03684        332        640: 100%|██████████| 1/1 [00:06<00:00,  6.79s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.69s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.69s/it]\n",
      "                   all         61        256   0.000714      0.014   0.000387   6.72e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "       9/49         0G     0.1078    0.08183    0.03655        265        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "       9/49         0G     0.1078    0.08183    0.03655        265        640: 100%|██████████| 1/1 [00:07<00:00,  7.06s/it]\n",
      "       9/49         0G     0.1078    0.08183    0.03655        265        640: 100%|██████████| 1/1 [00:07<00:00,  7.06s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.44s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.44s/it]\n",
      "                   all         61        256   0.000635     0.0125   0.000345   7.55e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      10/49         0G      0.107    0.06313     0.0368        191        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      10/49         0G      0.107    0.06313     0.0368        191        640: 100%|██████████| 1/1 [00:06<00:00,  6.68s/it]\n",
      "      10/49         0G      0.107    0.06313     0.0368        191        640: 100%|██████████| 1/1 [00:06<00:00,  6.68s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.61s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.61s/it]\n",
      "                   all         61        256   0.000635     0.0125   0.000345   9.27e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      11/49         0G     0.1068     0.0889    0.03658        317        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      11/49         0G     0.1068     0.0889    0.03658        317        640: 100%|██████████| 1/1 [00:06<00:00,  6.80s/it]\n",
      "      11/49         0G     0.1068     0.0889    0.03658        317        640: 100%|██████████| 1/1 [00:06<00:00,  6.80s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.36s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.36s/it]\n",
      "                   all         61        256   0.000694     0.0156   0.000378   0.000103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      12/49         0G     0.1049    0.07384    0.03654        257        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      12/49         0G     0.1049    0.07384    0.03654        257        640: 100%|██████████| 1/1 [00:07<00:00,  7.81s/it]\n",
      "      12/49         0G     0.1049    0.07384    0.03654        257        640: 100%|██████████| 1/1 [00:07<00:00,  7.81s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:10<00:00, 10.13s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:10<00:00, 10.13s/it]\n",
      "                   all         61        256   0.000582     0.0171   0.000326   9.28e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      13/49         0G     0.1078    0.08258    0.03652        303        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      13/49         0G     0.1078    0.08258    0.03652        303        640: 100%|██████████| 1/1 [00:07<00:00,  7.16s/it]\n",
      "      13/49         0G     0.1078    0.08258    0.03652        303        640: 100%|██████████| 1/1 [00:07<00:00,  7.16s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:09<00:00,  9.09s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:09<00:00,  9.09s/it]\n",
      "                   all         61        256   0.000556     0.0187   0.000315   9.67e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      14/49         0G     0.1068     0.1119    0.03604        447        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      14/49         0G     0.1068     0.1119    0.03604        447        640: 100%|██████████| 1/1 [00:07<00:00,  7.50s/it]\n",
      "      14/49         0G     0.1068     0.1119    0.03604        447        640: 100%|██████████| 1/1 [00:07<00:00,  7.50s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.69s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.70s/it]\n",
      "                   all         61        256   0.000513     0.0187   0.000291   9.37e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      15/49         0G     0.1042    0.08712    0.03549        286        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      15/49         0G     0.1042    0.08712    0.03549        286        640: 100%|██████████| 1/1 [00:07<00:00,  7.43s/it]\n",
      "      15/49         0G     0.1042    0.08712    0.03549        286        640: 100%|██████████| 1/1 [00:07<00:00,  7.43s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.44s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.44s/it]\n",
      "                   all         61        256   0.000444     0.0187   0.000258   8.56e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      16/49         0G     0.1056    0.08594     0.0356        321        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      16/49         0G     0.1056    0.08594     0.0356        321        640: 100%|██████████| 1/1 [00:06<00:00,  6.72s/it]\n",
      "      16/49         0G     0.1056    0.08594     0.0356        321        640: 100%|██████████| 1/1 [00:06<00:00,  6.72s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.47s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.47s/it]\n",
      "                   all         61        256   0.000538     0.0234    0.00032   0.000104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      17/49         0G     0.1033     0.1105    0.03596        370        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      17/49         0G     0.1033     0.1105    0.03596        370        640: 100%|██████████| 1/1 [00:06<00:00,  6.99s/it]\n",
      "      17/49         0G     0.1033     0.1105    0.03596        370        640: 100%|██████████| 1/1 [00:06<00:00,  6.99s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.60s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.60s/it]\n",
      "                   all         61        256   0.000625      0.028   0.000363   0.000108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      18/49         0G     0.1028    0.07493    0.03549        245        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      18/49         0G     0.1028    0.07493    0.03549        245        640: 100%|██████████| 1/1 [00:06<00:00,  6.88s/it]\n",
      "      18/49         0G     0.1028    0.07493    0.03549        245        640: 100%|██████████| 1/1 [00:06<00:00,  6.88s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.58s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.58s/it]\n",
      "                   all         61        256   0.000494     0.0187   0.000282   9.57e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      19/49         0G     0.1034     0.1131    0.03568        386        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      19/49         0G     0.1034     0.1131    0.03568        386        640: 100%|██████████| 1/1 [00:07<00:00,  7.28s/it]\n",
      "      19/49         0G     0.1034     0.1131    0.03568        386        640: 100%|██████████| 1/1 [00:07<00:00,  7.28s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.74s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.74s/it]\n",
      "                   all         61        256   0.000494     0.0187   0.000279   9.92e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      20/49         0G     0.1038    0.09854    0.03529        355        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      20/49         0G     0.1038    0.09854    0.03529        355        640: 100%|██████████| 1/1 [00:07<00:00,  7.08s/it]\n",
      "      20/49         0G     0.1038    0.09854    0.03529        355        640: 100%|██████████| 1/1 [00:07<00:00,  7.08s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.56s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.56s/it]\n",
      "                   all         61        256    0.00059     0.0265   0.000337   0.000108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      21/49         0G     0.1014    0.09853    0.03517        301        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      21/49         0G     0.1014    0.09853    0.03517        301        640: 100%|██████████| 1/1 [00:06<00:00,  6.85s/it]\n",
      "      21/49         0G     0.1014    0.09853    0.03517        301        640: 100%|██████████| 1/1 [00:06<00:00,  6.85s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.53s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.53s/it]\n",
      "                   all         61        256    0.00059     0.0265   0.000339   0.000108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      22/49         0G     0.1024    0.09564    0.03512        327        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      22/49         0G     0.1024    0.09564    0.03512        327        640: 100%|██████████| 1/1 [00:06<00:00,  6.87s/it]\n",
      "      22/49         0G     0.1024    0.09564    0.03512        327        640: 100%|██████████| 1/1 [00:06<00:00,  6.87s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.45s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.45s/it]\n",
      "                   all         61        256   0.000502     0.0218    0.00029   0.000102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      23/49         0G      0.104     0.1099    0.03533        389        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      23/49         0G      0.104     0.1099    0.03533        389        640: 100%|██████████| 1/1 [00:06<00:00,  6.87s/it]\n",
      "      23/49         0G      0.104     0.1099    0.03533        389        640: 100%|██████████| 1/1 [00:06<00:00,  6.87s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.64s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.64s/it]\n",
      "                   all         61        256   0.000502     0.0218    0.00029   0.000101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      24/49         0G     0.1038    0.07855    0.03431        290        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      24/49         0G     0.1038    0.07855    0.03431        290        640: 100%|██████████| 1/1 [00:06<00:00,  6.91s/it]\n",
      "      24/49         0G     0.1038    0.07855    0.03431        290        640: 100%|██████████| 1/1 [00:06<00:00,  6.91s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.73s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.73s/it]\n",
      "                   all         61        256    0.00046     0.0187   0.000261   9.41e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      25/49         0G     0.1027    0.08106    0.03419        268        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      25/49         0G     0.1027    0.08106    0.03419        268        640: 100%|██████████| 1/1 [00:07<00:00,  7.09s/it]\n",
      "      25/49         0G     0.1027    0.08106    0.03419        268        640: 100%|██████████| 1/1 [00:07<00:00,  7.09s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.75s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.75s/it]\n",
      "                   all         61        256   0.000476     0.0187   0.000269   9.73e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      26/49         0G     0.1034    0.06035    0.03498        207        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      26/49         0G     0.1034    0.06035    0.03498        207        640: 100%|██████████| 1/1 [00:07<00:00,  7.14s/it]\n",
      "      26/49         0G     0.1034    0.06035    0.03498        207        640: 100%|██████████| 1/1 [00:07<00:00,  7.14s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.76s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.76s/it]\n",
      "                   all         61        256   0.000625      0.028   0.000366   0.000107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      27/49         0G    0.09809    0.09575     0.0348        278        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      27/49         0G    0.09809    0.09575     0.0348        278        640: 100%|██████████| 1/1 [00:06<00:00,  6.80s/it]\n",
      "      27/49         0G    0.09809    0.09575     0.0348        278        640: 100%|██████████| 1/1 [00:06<00:00,  6.80s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.38s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.38s/it]\n",
      "                   all         61        256   0.000686     0.0327   0.000404   0.000109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      28/49         0G     0.1018    0.09696    0.03432        325        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      28/49         0G     0.1018    0.09696    0.03432        325        640: 100%|██████████| 1/1 [00:06<00:00,  6.91s/it]\n",
      "      28/49         0G     0.1018    0.09696    0.03432        325        640: 100%|██████████| 1/1 [00:06<00:00,  6.91s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.55s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.55s/it]\n",
      "                   all         61        256   0.000625      0.028   0.000364   0.000107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      29/49         0G    0.09809    0.08987    0.03486        253        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      29/49         0G    0.09809    0.08987    0.03486        253        640: 100%|██████████| 1/1 [00:07<00:00,  7.11s/it]\n",
      "      29/49         0G    0.09809    0.08987    0.03486        253        640: 100%|██████████| 1/1 [00:07<00:00,  7.11s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.67s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.67s/it]\n",
      "                   all         61        256   0.000444     0.0187   0.000249   8.44e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      30/49         0G      0.101     0.1089    0.03446        374        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      30/49         0G      0.101     0.1089    0.03446        374        640: 100%|██████████| 1/1 [00:07<00:00,  7.04s/it]\n",
      "      30/49         0G      0.101     0.1089    0.03446        374        640: 100%|██████████| 1/1 [00:07<00:00,  7.04s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.73s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.73s/it]\n",
      "                   all         61        256   0.000686     0.0327   0.000402   0.000106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      31/49         0G    0.09705    0.06532    0.03375        170        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      31/49         0G    0.09705    0.06532    0.03375        170        640: 100%|██████████| 1/1 [00:07<00:00,  7.11s/it]\n",
      "      31/49         0G    0.09705    0.06532    0.03375        170        640: 100%|██████████| 1/1 [00:07<00:00,  7.11s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.63s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.63s/it]\n",
      "                   all         61        256   0.000667     0.0327    0.00039   0.000105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      32/49         0G    0.09998     0.0818    0.03307        255        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      32/49         0G    0.09998     0.0818    0.03307        255        640: 100%|██████████| 1/1 [00:06<00:00,  6.99s/it]\n",
      "      32/49         0G    0.09998     0.0818    0.03307        255        640: 100%|██████████| 1/1 [00:06<00:00,  6.99s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.84s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.84s/it]\n",
      "                   all         61        256    0.00064     0.0296   0.000372   0.000107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      33/49         0G     0.1012    0.09953    0.03345        337        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      33/49         0G     0.1012    0.09953    0.03345        337        640: 100%|██████████| 1/1 [00:06<00:00,  6.83s/it]\n",
      "      33/49         0G     0.1012    0.09953    0.03345        337        640: 100%|██████████| 1/1 [00:06<00:00,  6.83s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.57s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.57s/it]\n",
      "                   all         61        256   0.000686     0.0327     0.0004    0.00011\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      34/49         0G     0.0988    0.08074    0.03356        236        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      34/49         0G     0.0988    0.08074    0.03356        236        640: 100%|██████████| 1/1 [00:07<00:00,  7.03s/it]\n",
      "      34/49         0G     0.0988    0.08074    0.03356        236        640: 100%|██████████| 1/1 [00:07<00:00,  7.03s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.47s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.47s/it]\n",
      "                   all         61        256   0.000667     0.0327   0.000389   0.000107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      35/49         0G     0.1026     0.1052    0.03438        388        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      35/49         0G     0.1026     0.1052    0.03438        388        640: 100%|██████████| 1/1 [00:06<00:00,  6.77s/it]\n",
      "      35/49         0G     0.1026     0.1052    0.03438        388        640: 100%|██████████| 1/1 [00:06<00:00,  6.77s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.68s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.68s/it]\n",
      "                   all         61        256   0.000538     0.0234   0.000309   9.88e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      36/49         0G    0.09517    0.07079    0.03423        176        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      36/49         0G    0.09517    0.07079    0.03423        176        640: 100%|██████████| 1/1 [00:07<00:00,  7.05s/it]\n",
      "      36/49         0G    0.09517    0.07079    0.03423        176        640: 100%|██████████| 1/1 [00:07<00:00,  7.05s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:09<00:00,  9.12s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:09<00:00,  9.12s/it]\n",
      "                   all         61        256   0.000444     0.0187   0.000245   8.37e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      37/49         0G    0.09732    0.09129    0.03295        256        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      37/49         0G    0.09732    0.09129    0.03295        256        640: 100%|██████████| 1/1 [00:07<00:00,  7.62s/it]\n",
      "      37/49         0G    0.09732    0.09129    0.03295        256        640: 100%|██████████| 1/1 [00:07<00:00,  7.62s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.92s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.92s/it]\n",
      "                   all         61        256   0.000476     0.0187   0.000264    9.2e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      38/49         0G    0.09713     0.1021    0.03369        291        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      38/49         0G    0.09713     0.1021    0.03369        291        640: 100%|██████████| 1/1 [00:06<00:00,  6.77s/it]\n",
      "      38/49         0G    0.09713     0.1021    0.03369        291        640: 100%|██████████| 1/1 [00:06<00:00,  6.77s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.51s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.51s/it]\n",
      "                   all         61        256   0.000538     0.0234    0.00031   9.67e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      39/49         0G    0.09912     0.0861    0.03369        270        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      39/49         0G    0.09912     0.0861    0.03369        270        640: 100%|██████████| 1/1 [00:06<00:00,  6.82s/it]\n",
      "      39/49         0G    0.09912     0.0861    0.03369        270        640: 100%|██████████| 1/1 [00:06<00:00,  6.82s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.83s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.83s/it]\n",
      "                   all         61        256   0.000538     0.0234   0.000309   9.67e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      40/49         0G    0.09884      0.102    0.03273        323        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      40/49         0G    0.09884      0.102    0.03273        323        640: 100%|██████████| 1/1 [00:06<00:00,  6.98s/it]\n",
      "      40/49         0G    0.09884      0.102    0.03273        323        640: 100%|██████████| 1/1 [00:06<00:00,  6.98s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.76s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.76s/it]\n",
      "                   all         61        256   0.000625      0.028   0.000362   0.000104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      41/49         0G    0.09716    0.07262    0.03293        202        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      41/49         0G    0.09716    0.07262    0.03293        202        640: 100%|██████████| 1/1 [00:06<00:00,  6.97s/it]\n",
      "      41/49         0G    0.09716    0.07262    0.03293        202        640: 100%|██████████| 1/1 [00:06<00:00,  6.97s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.73s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.73s/it]\n",
      "                   all         61        256   0.000625      0.028   0.000366   0.000107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      42/49         0G    0.09742    0.07773    0.03252        234        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      42/49         0G    0.09742    0.07773    0.03252        234        640: 100%|██████████| 1/1 [00:06<00:00,  6.85s/it]\n",
      "      42/49         0G    0.09742    0.07773    0.03252        234        640: 100%|██████████| 1/1 [00:06<00:00,  6.85s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.47s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.47s/it]\n",
      "                   all         61        256   0.000667     0.0327   0.000388   0.000105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      43/49         0G    0.09597     0.1031    0.03286        289        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      43/49         0G    0.09597     0.1031    0.03286        289        640: 100%|██████████| 1/1 [00:06<00:00,  6.65s/it]\n",
      "      43/49         0G    0.09597     0.1031    0.03286        289        640: 100%|██████████| 1/1 [00:06<00:00,  6.65s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.51s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.51s/it]\n",
      "                   all         61        256   0.000686     0.0327   0.000405   0.000108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      44/49         0G    0.09295    0.08765    0.03303        217        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      44/49         0G    0.09295    0.08765    0.03303        217        640: 100%|██████████| 1/1 [00:06<00:00,  6.64s/it]\n",
      "      44/49         0G    0.09295    0.08765    0.03303        217        640: 100%|██████████| 1/1 [00:06<00:00,  6.64s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.42s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.42s/it]\n",
      "                   all         61        256   0.000631     0.0327   0.000367   9.91e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      45/49         0G    0.09978     0.1144    0.03213        393        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      45/49         0G    0.09978     0.1144    0.03213        393        640: 100%|██████████| 1/1 [00:06<00:00,  6.58s/it]\n",
      "      45/49         0G    0.09978     0.1144    0.03213        393        640: 100%|██████████| 1/1 [00:06<00:00,  6.58s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.60s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.60s/it]\n",
      "                   all         61        256   0.000625      0.028   0.000359   0.000106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      46/49         0G     0.1008    0.09634    0.03355        330        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      46/49         0G     0.1008    0.09634    0.03355        330        640: 100%|██████████| 1/1 [00:06<00:00,  6.74s/it]\n",
      "      46/49         0G     0.1008    0.09634    0.03355        330        640: 100%|██████████| 1/1 [00:06<00:00,  6.74s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.62s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.62s/it]\n",
      "                   all         61        256    0.00064     0.0296   0.000374   0.000105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      47/49         0G    0.09826    0.09166    0.03377        286        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      47/49         0G    0.09826    0.09166    0.03377        286        640: 100%|██████████| 1/1 [00:06<00:00,  6.84s/it]\n",
      "      47/49         0G    0.09826    0.09166    0.03377        286        640: 100%|██████████| 1/1 [00:06<00:00,  6.84s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.57s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.57s/it]\n",
      "                   all         61        256   0.000625      0.028   0.000364   0.000106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      48/49         0G    0.09508     0.1123    0.03275        321        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      48/49         0G    0.09508     0.1123    0.03275        321        640: 100%|██████████| 1/1 [00:06<00:00,  6.80s/it]\n",
      "      48/49         0G    0.09508     0.1123    0.03275        321        640: 100%|██████████| 1/1 [00:06<00:00,  6.80s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.78s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.78s/it]\n",
      "                   all         61        256   0.000625      0.028   0.000365   0.000104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "      49/49         0G    0.09589    0.08235    0.03194        246        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      49/49         0G    0.09589    0.08235    0.03194        246        640: 100%|██████████| 1/1 [00:06<00:00,  6.93s/it]\n",
      "      49/49         0G    0.09589    0.08235    0.03194        246        640: 100%|██████████| 1/1 [00:06<00:00,  6.93s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.79s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.79s/it]\n",
      "                   all         61        256   0.000444     0.0187   0.000248   8.36e-05\n",
      "\n",
      "50 epochs completed in 0.224 hours.\n",
      "Optimizer stripped from yolov5\\runs\\train\\yolov5s_results4\\weights\\last.pt, 14.9MB\n",
      "Optimizer stripped from yolov5\\runs\\train\\yolov5s_results4\\weights\\best.pt, 14.9MB\n",
      "\n",
      "Validating yolov5\\runs\\train\\yolov5s_results4\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 182 layers, 7251912 parameters, 0 gradients\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 3.550s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.44s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:08<00:00,  8.44s/it]\n",
      "                   all         61        256   0.000538     0.0234    0.00031   9.72e-05\n",
      "             with_mask         61        214    0.00161     0.0701   0.000931   0.000292\n",
      " mask_weared_incorrect         61         10          0          0          0          0\n",
      "          without_mask         61         32          0          0          0          0\n",
      "Results saved to \u001b[1myolov5\\runs\\train\\yolov5s_results4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start = datetime.now()\n",
    "!python C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\train.py --img 640 --batch 32 --epochs 50 --data C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\data.yaml --cfg C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\models\\custom_yolov5s.yaml --weights yolov5s.pt --name yolov5s_results  --cache\n",
    "end = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime = 0:16:05.007036\n"
     ]
    }
   ],
   "source": [
    "print(\"Runtime =\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(r\"C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\runs\\train\\yolov5s_results4\\train_batch0.jpg\")\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['C:\\\\Users\\\\Kevem\\\\OneDrive\\\\Documents\\\\GitHub\\\\FaceMaskDetector\\\\Dataset\\\\Output\\\\yolov5\\\\yolov5\\\\runs\\\\train\\\\yolov5s_results4\\\\weights\\\\best.pt'], source=data/test/images/, data=yolov5\\data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_format=0, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5\\runs\\detect, name=expTestImage, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5  v7.0-392-gf003c3df Python-3.12.8 torch-2.5.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 182 layers, 7251912 parameters, 0 gradients\n",
      "image 1/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss1.png: 480x640 (no detections), 77.0ms\n",
      "image 2/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss102.png: 480x640 (no detections), 55.9ms\n",
      "image 3/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss126.png: 480x640 (no detections), 57.4ms\n",
      "image 4/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss130.png: 480x640 (no detections), 58.9ms\n",
      "image 5/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss172.png: 480x640 (no detections), 56.8ms\n",
      "image 6/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss215.png: 480x640 (no detections), 59.4ms\n",
      "image 7/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss219.png: 480x640 (no detections), 57.1ms\n",
      "image 8/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss220.png: 480x640 (no detections), 63.1ms\n",
      "image 9/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss240.png: 480x640 (no detections), 59.6ms\n",
      "image 10/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss284.png: 480x640 (no detections), 60.1ms\n",
      "image 11/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss316.png: 480x640 (no detections), 60.1ms\n",
      "image 12/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss340.png: 480x640 (no detections), 58.6ms\n",
      "image 13/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss386.png: 480x640 (no detections), 59.6ms\n",
      "image 14/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss44.png: 480x640 (no detections), 58.6ms\n",
      "image 15/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss450.png: 480x640 (no detections), 60.2ms\n",
      "image 16/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss453.png: 480x640 (no detections), 58.5ms\n",
      "image 17/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss465.png: 480x640 (no detections), 57.6ms\n",
      "image 18/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss500.png: 480x640 (no detections), 57.5ms\n",
      "image 19/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss616.png: 480x640 (no detections), 55.0ms\n",
      "image 20/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss625.png: 480x640 (no detections), 53.9ms\n",
      "image 21/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss646.png: 480x640 (no detections), 56.0ms\n",
      "image 22/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss674.png: 480x640 (no detections), 57.5ms\n",
      "image 23/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss698.png: 480x640 (no detections), 61.3ms\n",
      "image 24/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss778.png: 480x640 (no detections), 60.2ms\n",
      "image 25/25 C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\data\\test\\images\\maksssksksss844.png: 480x640 (no detections), 64.8ms\n",
      "Speed: 0.2ms pre-process, 59.4ms inference, 0.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5\\runs\\detect\\expTestImage2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\detect.py --source data/test/images/ --weight C:\\Users\\Kevem\\OneDrive\\Documents\\GitHub\\FaceMaskDetector\\Dataset\\Output\\yolov5\\yolov5\\runs\\train\\yolov5s_results4\\weights\\best.pt --name expTestImage --conf 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {\n",
    "    'with_mask': (0, 255, 0),\n",
    "    'mask_weared_incorrect':  (0, 0, 255),\n",
    "    'without_mask': (255, 0, 0) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img_id):\n",
    "    df_image = df[df.file==img_id]\n",
    "    df_image[['xmin', 'ymin', 'xmax', 'ymax']] = df_image[['xmin', 'ymin', 'xmax', 'ymax']].astype('int64')\n",
    "    path = 'data/test/images/'+img_id# +'.png'\n",
    "    img = plt.imread(path)\n",
    "\n",
    "    imge = img.copy()\n",
    "\n",
    "    for index in range(len(df_image)):\n",
    "        row = df_image.iloc[index]\n",
    "        cv2.rectangle(imge, \n",
    "                      (row['xmin'], row['ymin']),\n",
    "                      (row['xmax'], row['ymax']),\n",
    "                      color=color_dict[row['name']],\n",
    "                      thickness=2)\n",
    "\n",
    "    img_pred = plt.imread('runs/detect/expTestImage/'+img_id)\n",
    "    # ===================================\n",
    "    plt.figure(figsize=(14,17))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(imge)\n",
    "    plt.axis('off')\n",
    "    plt.title('Image with Truth Box')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(img_pred)\n",
    "    plt.axis('off')\n",
    "    plt.title('Image with Predicted Box')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
